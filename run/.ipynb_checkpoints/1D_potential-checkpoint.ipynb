{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a8b3ef",
   "metadata": {},
   "source": [
    "# TMD maps with one-D potential \n",
    "\n",
    "Here we will aim to measure the effect of prefactor reduction in a 1D case of TMD map. Note that our error model is of the form: \n",
    "\n",
    "$$ |L^{(n)}_{\\epsilon,\\mu}f(x) - \\mathcal{L}f(x)| \\sim \\frac{V(x)}{\\sqrt{n}\\epsilon^{2 + d/4}} + \\epsilon B(x) $$\n",
    "\n",
    "Here $V$ and $B$ are variance and bias error prefactors respectively. The 1-D setup is as follows: \n",
    "\n",
    "1. $V: \\mathbb{R} \\to \\mathbb{R}$ is a (coercive) potential. \n",
    "2. The system $X_t$ is governed by the SDE: \n",
    "$\\begin{align}dX_t = -\\nabla V(X_t) + \\sqrt{2\\beta^{-1}} dW_t \\end{align} $\n",
    "3. The ergodic measure is $\\propto \\exp{\\left(-\\beta V(x)\\right)}$\n",
    "4. The committor satisfies: \n",
    "$$\\begin{align}\\Delta q - \\beta\\nabla V(x) \\cdot \\nabla q(x) = 0,\\:\\: q\\mid_{\\partial A} = 0\\, q\\mid_{\\partial B} = 1 \\end{align}$$\n",
    "\n",
    "Here $A = \\{x < a\\}$, $B = \\{x > b\\}$. The committor function can be given analytically for $x \\in (a,b)$: \n",
    "\n",
    "$$ q(x) = \\frac{\\int_{a}^{x}\\exp{\\left(-\\beta V(x)\\right)}\\,dx}{\\int_{a}^{b}\\exp{\\left(-\\beta V(x)\\right)}\\,dx}$$\n",
    "\n",
    "A good 1-D potential is \n",
    "\n",
    "$$ V(x) = (x^2 - 1)^2 $$\n",
    "\n",
    "We set \n",
    "\n",
    "$$ A = \\{x < -0.8 \\}, \\: B = \\{x > -0.8 \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import sys \n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),'..')))\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Regular Modules\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import scipy.integrate as scint\n",
    "#from numpy.random import default_rng\n",
    "import numpy.ma as ma\n",
    "import matplotlib.tri as tri\n",
    "import scipy.io\n",
    "import time \n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import argparse\n",
    "\n",
    "# parallelization modules \n",
    "from math import nan\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocess\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "# # My Modules\n",
    "import src.model_systems as model_systems\n",
    "import src.helpers as helpers\n",
    "import src.potentials as potentials\n",
    "import src.diffusion_map as diffusion_map\n",
    "from src.fem.distmesh import * \n",
    "from src.fem.FEM_TPT import *\n",
    "import src.sampling as sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464ea8d",
   "metadata": {},
   "source": [
    "How to do this: \n",
    "\n",
    "1. Set up drift, potential, invariant measure, committor. \n",
    "\n",
    "2. Set up two datasets: uniform, normal random variable centered @ 0. \n",
    "\n",
    "3. Set up TMD map kernel for each set. This will involve picking epsilon, N. Don't use knn sparsification. Compare KDE's. \n",
    "\n",
    "4. Approximate $\\mathcal{L}$ on some simple $f$ (say $f = x^5 - x$) by plugging in the analytical form for $\\mathcal{L}f = f'' - V'(x)f'(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cd3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up params\n",
    "beta = 1 \n",
    "d = 1\n",
    "def potential(x): \n",
    "    return (x**2 - 1)**2 \n",
    "\n",
    "def drift(x): \n",
    "    return 4*x*(x**2 - 1)\n",
    "\n",
    "Z = scint.quad(lambda x: np.exp(-beta*potential(x)), -50, 50)[0]\n",
    "\n",
    "def mu(x): return (1/Z)*np.exp(-beta*potential(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcd5a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset \n",
    "\n",
    "N = int(1e6)\n",
    "uniform = np.linspace(-2,2,int(N+1)).reshape(N+1,d) # note that p = uniform[0,N/2]\n",
    "biased = np.random.randn(int(N+1)).reshape(N+1,d) # p = biased[N]\n",
    "biased[N,0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04818bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up TMD map kernel \n",
    "\n",
    "target_measure_uniform = np.zeros(N+1)\n",
    "target_measure_biased = np.zeros(N+1)\n",
    "\n",
    "for i in range(N+1):\n",
    "    target_measure_uniform[i] = mu(uniform[i,:])\n",
    "    target_measure_biased[i] = mu(biased[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fccbd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ = 1/(10**(6/5))\n",
    "target_dmap_uniform = diffusion_map.TargetMeasureDiffusionMap(epsilon=ϵ, n_neigh=N, \\\n",
    "                                                          target_measure=target_measure_uniform)\n",
    "target_dmap_uniform.construct_generator(uniform.T)\n",
    "K_uniform = target_dmap_uniform.get_kernel()\n",
    "L_uniform = target_dmap_uniform.get_generator() \n",
    "\n",
    "target_dmap_biased = diffusion_map.TargetMeasureDiffusionMap(epsilon=ϵ, n_neigh=N, \\\n",
    "                                                          target_measure=target_measure_biased)\n",
    "target_dmap_biased.construct_generator(biased.T)\n",
    "K_biased = target_dmap.get_kernel()\n",
    "L_uniform = target_dmap.get_generator() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9d3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
